% $Log: abstract.tex,v $
% Revision 1.1  93/05/14  14:56:25  starflt
% Initial revision
% 
% Revision 1.1  90/05/04  10:41:01  lwvanels
% Initial revision
% 
%
%% The text of your abstract and nothing else (other than comments) goes here.
%% It will be single-spaced and the rest of the text that is supposed to go on
%% the abstract page will be generated by the abstractpage environment.  This
%% file should be \input (not \include 'd) from cover.tex.

In this thesis, I designed, prototyped and benchmarked two different data partitioning strategies for social network type data. The first strategy takes advantage of  the heavy-tailed degree distributions of social networks, to optimize the latency of vertex neighborhood queries. The second strategy takes advantage of the high temporal locality of workloads to improve latencies for vertex neighborhood intersection queries. Both techniques aim to shorten the tail of the latency distribution, while trying to avoid decreasing write performance and system throughput compared to the current hashing approach. The strategies presented are evaluated using synthetic data as well as real workloads provided by Twitter, and show promising improvements in latency at some cost in system complexity.

%% In this thesis, I designed and implemented a compiler which performs
%% optimizations that reduce the number of low-level floating point operations
%% necessary for a specific task; this involves the optimization of chains of
%% floating point operations as well as the implementation of a ``fixed'' point
%% data type that allows some floating point operations to simulated with integer
%% arithmetic.  The source language of the compiler is a subset of C, and the
%% destination language is assembly language for a micro-floating point CPU.  An
%% instruction-level simulator of the CPU was written to allow testing of the
%% code.  A series of test pieces of codes was compiled, both with and without
%% optimization, to determine how effective these optimizations were.
