\documentclass{article}
\usepackage{todonotes, listings}
\author{Oscar Moll-Thomae}
\title{Proposal and work in progress}
\begin{document}
\maketitle

% for verbatim: \verb!int m, n;!
% another option: ttfamily

\newcommand{\code}{\ttfamily}
\newcommand{\draftnote}[2][inline]{\todo[#1]{{\bf NOTE:} #2}}
\newcommand{\todonote}[2][inline]{\todo[#1]{{\bf TODO:} #2}}

%todo: figure out way of placing arguments to those ops (see the if then else thing)
%todo: figure out way to make text wider
\newcommand{\edgeq}{{\code getEdge()}}
\newcommand{\fanoutq}[1][]{{\code getFanout(}~#1~{\code )}}
\newcommand{\intersectq}{{\code getIntersection()}}
\newcommand{\randomwalk}{{\code randomWalk()}}

\bibliographystyle{alpha}


\section{Overview}

At Twitter, there are three main types of query operations expected of the graph store interface. One is querying for edge metadata given the two endpoints {\code getEdge(v,w)}. Metadata includes values such as a timestamp for when the edge was created, and qualifiers for edge such as whether this represents a simple 'follow', or also a  'follow via sms', or even a ''blocked'. Edges are directed, and there need not be symmetry.  A follows B does not imply B follows A, but A follows B is a fact that may be queired via both A and B. At the application level, this enables the site to inform the user  'do I follow person B?' by displaying this fact on a user's profile, or by coloring the 'Follow' button differently to indicate this is already the case.   

The second one is, given a vertex, return all its adjacent vertices. In a directed graph, there are two directions
to choose from. Moreover, there are variations on this, we can ask for user given number of vertices, for example the latest one, or all the   {\code getFanout(v)}, The fanout operation with a limited page size enables site visitors to look at the first few followers as well as the first few people a person follows.   Most importantly, the fanout operation enables tweet routing and delivery. Depending on the timeline materialization strategy, Whenever @LadyGaga tweets, the effects of that action must be propagated to @omoll and  everyone else following her in a way that allows for later retrieval.  Or alternatively whenver @ladyGaga signs into the service, tweets from all the people she follows can be retrieved and merged to materilize her timeline. Either of these methods, or a hybrid strategy, need of the fanout operation.

Finally the third query operation is the intersection of the neighbors of two nodes: {\code getIntersection(v,w)}.
There are several important use cases for this operation. When a user visits a friends page, we may want to show a limited set of common friends.  When a user visits a stranger's profile page, it may be useful to show them friends that already are following that stranger to encourage a follow.

Semantics of intersection: just like getting the fanouts we wish, and then intersecting them outside.
The only update is to add, modify or delete an edge or its metadata.

% other compelling uses of the store could be discussed. eg naive recommendation., more complicated 

A real workload is made of a mix of these queries and updates. Based on the query logs, the most   query My thesis focuses on the effect different partitioning techniques have on performance. The measure I use for performance is the latency of the individual queries.  

but  I am thinking of  partitioning strategies by starting with one of the operations and thinking backward to something that would improve their performance. For that reason, the benchmarks I have in mind are: 100\% \edgeq, 100\% \fanoutq, 100\% \intersectq and a mix
with realistic twitter proportions. \todonote[fancyline]{put workload numbers from wiki here}. 
xo
The thoughts on strategies are here:

\begin{enumerate}
\item \edgeq: no strategy targets to optimize this in particular, but we should know clearly whether they  perform well on this.
\item \fanoutq: fanouts in a graph with wide variation in degree would improve with treating popular users differntly. The amount of benefit from this depends on several factors. A first factor is whether nodes with large degree
have fanouts more often than nodes with smaller followings. Another factor is whether the rest of the system takes advantage of the parallelism in this optmized \fanoutq.  \draftnote{I am not worrying about the rest of the system for my thesis, but in reality it would matter if the client does not process stuff in parallel. Also, looking at actual data from queries would help me 1) model simulated workloads, 2) talk about it in this text}
\item \intersectq: pairs that historically intersect often should be stored together. \draftnote{again, i need historical data to effectively model this}
\item \randomwalk: cluster actual graph, replicate. \todonote{talk to Raghavendra, Pankaj about this, and try reading more about it. This operation seems less important but kind of exciting, and would give room to looking at other kinds of work.  Separate note: A stab at interface: could be some thing like {\code List<Pair<Node,Int>> randomWalkFrom(v, depth)} where hopefully depth is 2 or 3, for example. Also, this kind of query can return an approximate, potentially inaccurate result if this results in faster, online versions of it}
\end{enumerate}

This thesis presents three sections. The first is the design of three strategies based on the actual api operations we would like to support. \draftnote{Some iteration on design necessarily involves looking at real data (to get a better feel for what won't be effective). For example, I have used what Raghavendra emailed in September to evaluate viability for the \fanoutq strategy.} Second is the definiton and results of simulated workloads on a bare bones version of a distributed graph db.This bare bones version is not intended to deal with failures nor with online resharding/rebalancing.  In simulated workloads I have the option of changing things like skew, correlations and simulatied graph structure, the more I know about the real ones the better I can decide what to vary and to design the benchmark generator with it in mind. Finally, while the simulation gives the thesis a more general conceptual coverage because I can explore different parameters, sizes and hypothetical scenarios, the third section is the integration and benchmarking of the strategies on Twitter's graph service. 

\draftnote{right now I want to focus on getting infrastructure/benchmarks done for the \fanoutq and \intersectq before looking at the other stuff. This week I am trying to get to run a simulated workload good enough to make meaningful graphs about \fanoutq from it and write them up in this document. You can check what I have done so far on that front in my repo, or on the review}

\draftnote{one nice distinction made in the Zynga techtalk was the difference between a social graph (ie follows that happened at any time in the past), and the 'active' social graph, where the edges disappear unless there is recent activity, this kind of query is of a lot of interest for monitoring growth/etc. How would a graph store facilitate this, if at all?, and, how does this tie in with looking at query logs to identify 'active pairs' and 'active users' (to optimize intersections and fanouts respectively. Also, recommendations that use the active social graph may be better than plain static social graph.}


\todonote{think about performance effects of doing these reads while there are updates happening}
\draftnote{Don't read the rest, its taken from the wiki, and its more of a text dump}

\draftnote{relation between keeping this type of lookup table and caching. conceptually, both depend on there being a non-uniform access pattern that we can exploit to improve performance. Also think about how a cache keeps up to date}


\section{background and reading}

Physical Database Design Decision Algorithms and
Concurrent Reorganization for
Parallel Database Systems
by
Daniel C. Zilio -- proposes a particular search algorithm (some kind of branch and bound)
-- but also gives overview of approaches and 
-- more general than the single graph case (multiple tables)
--TODO: look up what it says about something like the many to many Twitter queries


Parallel static and dynamic
multi-constraint graph
partitioning‡
Kirk Schloegel∗,†, George Karypis and Vipin Kumar
--graph partitioning algorithms (both static and dynamic repartitioning) as used in graphical mesh partitioning.

---Notes on partitioning the Graph:
Tried partitioning. Challenges 
1: getting to the required format. The job ran as desired but the parity of the # edges was not right. (roughly good though)

2: METIS it chokes on the query graph.
Actually, METIS can handle larger #edges/#vertices/#weight totals by recompiling with larger types, 
except METIS took to long with a graph of params vertex:127046986  edges:692314 (011 weighted vertices and edges)  with a vertex weight sum of
also, it failed silently when I ran this same graph with a smaller data type, giving malformed partitions.
In the 64 bit case I stopped it after 3 days of running with 8 GB of memory 100% cpu, and it indicated it had been stopped
during 'initial' partitioning.

Next step is regenerating the graph with query based vertex weights.


3: PROBABLY metis cannot handle a graph of that size.


(paper of Newman and Park) Why social networks differ from other types of networks:
bascially two ways: positive degree correlation between neighbors is one feature, and higher than random clustering is the other.
In a social network, if a node has high degree then its neighbors are more likely to also have  high degree. 
(I wonder how this applies to 'asymetric' implication for Twitter, for example, 

is it that if a node has a lot of followers then it is likely to follow people with lots of followers?
or is it that if a node has lots of followers then it is likely following nodes with lots of followers?
recall, the follows graph is not symmetric but it is very heavily so. apparently. (Stu mentioned this).
 
In a social network, if A is connected to B and B to C, then it is likely A is connected to C. one explanation is
that people actively try to add the missing edges.  In Twitter, if A follows B and B follows C, recommendations are mde
so that A follows C. and if A follows B and A visits C, it is mentioned that B follows C, so that again the link A-C is encouraged.


Other observations:

-load may also be ameliorated by reading from the safety replicas we already have to make anyway.
-When we hash partition by u in (u,v), all edge queries for  u go to the same node, so edge query performance may deteriorate?
(counterargument: popular nodes will be spread across machines). So its not about one machine taking too long necessarily, but
about the query taking long in a single machine, when all queries could be done faster if we parallelize.


-Optimizing for latency. maximum throughput is a system characteristic. (added, we would do well, in documenting the max throughput) 
-even if optimizing for latency, if 2 clients can go all their queries in parallel and latency stays the same? can try checking whats the max number
of clients possible that keep latency low. Can throughput be increased simply by adding more machines? or does communication or a sequential component hinder that.
-replication effects on latency: assuming replicated backedges diminishes read latency for fanout and fanin queries, but makes a put requests double the work.
-replicating important  nodes also can speed up queries such as intersections but increase work at write time.
-(eg. an immutable graph could fit in a single machine, but writes would be impossible)
-when comparing different methods on reads must make sure not to be making gains based on adding work at write time
-effect of queries with only partial results on intersection/fanout
-validation of graph skew correlation with query skew. Are popular users also most likely to tweet often?  In the case of files,
the sizes are power law distributed, but this skew is not correlated with file access popularity. (Graph Structure of the Web by Broder).
In the case of social graphs, correlation would be: lady gaga and the like tweet the most (validate) this seems unlikely (only 1000 used)
On the other 

-replication in a graph of this type (eg facebook) if we replicate stuff 5 hops away, we replicate a lot of the graph, it is not even possible.
This kind of connectivity property of the graph has real system consequences.   

-queries that are looking for a graph pattern (follows is one, but there can be more complicated ones)
-queries that look for all the matches to one patter, as opposed to  a unique nodes.

-Other properties: triangles are more likely to exist.

Other exploration: (from Madden)
-profile the latency involved in a single fanout query, check where time is spent.
-make a cost model of the system as a function of #nodes, degree. determine when it is profitable to split.
-learn the cost model parameters from the data, then get optimal from that and the model.
-define the random walk operation. eg take in 1 node. and return a dictionary of other nodes/relative weights.
-is the random walk operaton more like an analitic query ('get random walk for everyone')


-can generate full graph with forwards and backwards edge without remembering it (just remembering the counts)
 (this will be useful for generating actual graphs)

problems:
-finding a good partition:
graph based (pujol paper), workload based partitioning (schism), 

-implementing directory:
hash function (control), best effort cache (madden paper), compressed/degraded table (trees), 

-make approach robust to update:
see survey of methods for repartitioning
pujol etal. use heursitics to make incremental changes to the graph as inserts happen.
SCHISM is less robust in this case and does not seem to address how to repartition.

-Pujol paper on social graph partitioning techniques: (Divide and conquer: partitioning online social networks)

Social graphs are different from other graphs in several ways: degree skew, 'assortative mixing' (in this case high degree tends to link to high degree), 
stronger clustering.
There is also some geolocality. people who identify with a certain locality tend to have edges to other people of that sort. (explore further) (assortativity)
Traffic properties: mostly one hop. fanouts and conversations. 
Idea: an algorithm that captures 'social closeness' in some sense, should score well in both 'fanout' costs and
conversations across the network. As well as follows graph edges.
Comparison: METIS, MO+ (modularity objective expanded to restrict the imbalances in sizes of natural communities)

Interestingly, natural communities tend to have a skewed size distribution as well, so trying to partition by community needs to deal 
with this skewed property of graphs.  MO+ does this by recursively splitting large modules. 

Results.  GP comm cost performance declines sharply as # of partitions increases. Imbalance is slightly higher.
MO+ remains better in terms of both comm cost and load imbalance.
Random is by far worst in com cost and rapidly drops too, but very little imbalance.

Karypis paper on METIS limitations for social graphs:

Typical heuristic for metis is you have a graph, you generate a matching and coarsen. 
To generate a matching, normally they will rank edges in some way and then go through them, adding them 
as long as they remain a matching. For ranking, weights are useful. (heavy edge matching)
With social networks, the degree skew is such that the coarsening will not progress much. 
(Example: star). So they improve performance by modifying the coarsening stage. 1) they relax the requirement it be an actual
matching (conversely they limit the size of clusters) 2) they define a different ranking function. (based on stuff including graph related info)
in that way, they improve the coarsening phase. (cannot find a way of using it for my own though)x


The Little Engines that Could. (also by Pujol)


All three suggested performance metrics are well aligned.


---

Partitioning in Apache Giraph. Master needs sorted list of vertices, generates ranges. Workers further divide the ranges, and may move them 
across at future steps of the step sequence of the model. 
It supports balancing by # vertices, # edges or a supplied custom partitioner. (not sure if it can take into accoutn graph connectivity etc.), or if it can 
do somethign thats not range partitioning.  (check?)
-----

Cassowary (check for upcoming blog post). stores graph in a single machine. will eventually need to be partitioned.
interface:
-cosine similarity
-ranom walk on a node (get a weighted set of neighbors) -> personalized recommendations
Real graph: (real time)
-hadoop job. recent interactions, exponential decay. 9B edges
out dist power law coeff is 2.1 
in dist: coeff is 1.8




\section{Benchmark design}
%some sources: \cite{Gray.Benchmark}, \cite{ycsb}, \cite{zipf-systems}

The zipf distribution is widely used as a valuable tool in benchmarking because of its natural emergence in a variety of applications. (refer to YCSB, gray paper, newman paper, huberman and Adamic: 
Zipf’s law and the Internet) Its existence complicates things for partitioning BUT helps make caching possible. We also exploit this empirical feature in our system.

Generating it takes work.

It is expected that splitting a heavy node \( A \)  decreases latency for a \fanoutq[ A ] query, due to its parallel execution.  But it is also clear the amount of work and resources to use remain at about the same (or worse, given the extra communication).  Such a system, when compared to a different one that keeps all edges \( \left(A, * \right) \) in the same storage node  will nontheless perform with higher throughput under a load of repeated \fanoutq[A] calls, since it is a single node processing all of them.  On the other hand, on under a load of \fanoutq{*} queries where the argument varies uniformly over different nodes $A$, $B$, ... The more evenly this happens, the more uniform the load is spread. Hence, under this workload the throughput would be very similar for both systems.    

Sampling a log involves sampling a graph. (really?) why not just sample the log and then define the graph from there? need to think about this.
But, starting witha  subset of the graph to use,  is also hard.
Sampling methodology:graph needs to be sampled in a way that preserves properties relevant to system performance (other than scale). Turns out sampling a graph while keeping all these properties
representative is not easy. (Leskovec paper). We used a historical graph for that same reason.

Then we sample by making each individual machine (60) log desired number of queries/ 60. Assumes each machine is getting a similar amount of queries over time, which seems to be the case.
Timestamps included. to validate that.

\draftnote{I could/should  write an explitic model for these simple scenarios, it would make it clearer and improve this from its current prose}

So here are four extremes:

A single vertex has all edges and  all queries go for it (actually they must):

Many vertices, all queries go to one:

Many vertices, a really heavy one, but queries go to all:

Even degree vertices, evenly spread queries:
-max possible throughput.

Sampling the graph. \draftnote{cite Leskovec Faloutsos paper. Also remember the other paper about predicting edges, which could be used for a third strategy. This third strategy can be place nodes likely to get edges together}

\subsection{Graph Partitioning}

-Generate METIS format graph from query log.
metis solves: 'minimize crossed edges subject to balanced partitions'
whats the weight of a partition? sum of vertex weights
What do we want to balance:
-information per server (number of edges)
-load per server (based on log?). make vertex weights be: social graph degree, #queries, 
-METIS graph edges are: frequency of intersection ocurrences.
-(note METRIS graph degree is # intersection queries involving the node)

Run partitioning algorithm.

load (empirical? or some other) graph based on partitioning information from file.

control: hash by edges, hash by vertex. comparison: two-tier.
-use real workload on real graph.

synthetic?:
-parallelization vs location.
-change query skew? the larger the skew in the queries
the 


-other ideas:
-effect of this strategy on fanouts /edges? -
-effect of limit queries? -
-another approach: insted of reacting, place edges together that will tend to have edges in the future. (how does this contrast with putting the ones together that already have them?)
I think they mention this either in the SCHISM or the Lookup Tables paper.

-another idea is you use the distinction between fanout and fanin, for small users you can store them together. for large users you store them separately thus naturally partitioning them.
- how about using the multiweight of the graph  to balance #fanouts queries as well as #edges.

\section{real data description}

Real graph 16B edges, 500M vertices.
max 16 million followers, median 60 followers.
\
Benchmark graph: 6B edges, 130 vertices
Query patterns:  (see files)

Workload:
~10 million different Ids in the queries, vast diversity in the fanouts part.
fanouts 9 million. intersection/edge, 1 million.
the intersection query graph has only about 1.3 million.

Skews (see files).

emails citations
Data model details:

Edge metadata is stored in Redis hashes. An edge A->B is stored with key = A, field = B and value = N bytes metadata (configurable). Userids are 32 bit integers encoded into a fixed length byte[] (start at 100M, increase sequentially). Edge metadata is a byte buffer, each byte is Byte.MAX_VALUE. hash-max-zipmap-value is fixed at 64.

Indexes are stored as userid -> sorted_set(adjacent_userids). Sort key is an int64 timestamp in millis. Index keys have a 1 byte prefix to distinguish from hash keys, so are 5 bytes each.

This time I also used a more realistic 70-20-10 query distribution for getMetadata(A), getFollowers(A) and getFollowings(A) rather than just the (cheaper) getMetadata(A) that I used last time.

16K qps
0.6ms (avg), 1ms (99%), 2ms (99.9%), 4ms (99.99%)

72K qps
0.7ms (avg), 2ms (99%), 2ms (99.9%), 4ms (99.99%)

136K qps
0.7ms (avg), 3ms (99%), 5ms (99.9%), 10ms (99.99%)

-------------

Most of our performance benchmarking so far has been for short durations, i.e. stretches of a few minutes at a time. Also, the workloads have been reads only. So I conducted a new test that ran for 72 hours and had the following request distribution (which we believe to be realistic): getEdgeMetadata (67%), getFollowings (15%), getFollowers (8%) and writes (10%). The writes had a 50-50 distribution of addNewEdge and deleteEdge operations. The operations transactionally updated the Redis edge metadata hash as well as follower index sorted set.

This test used a 72G RAM server machine running 20 Redis instances and a client machine on a different rack running a Java client talking directly to the Redis instances. The client ran with 85 threads to drive a workload of 130K-150K qps. Here is a summary of the latency/throughput:

Total queries: 36266319360
Total time (seconds): 259200
Qps: 139916
Latencies (ms) [99%, 99.9%, 99.99%]: 1 3 4

Note that these latencies include the write operations. Full latency distribution is available in the log file at nest1.corp.twitter.com:/home/rvp/redis_multi_day for those curious. 

Conclusion: results we saw earlier hold up over the long duration tests as well as with read/write workloads.

sum of histogram:
5305208505

wc in_edges.txt: 99883011  199766022 1172068249 in_edges.txt

wc out_edges.txt: 115814616  231629232 1390216278 out_edges.txt

done marker:
[ 08-50_05-Sep-2010 248 ] Crawled #idsBlocks = 187084 maxNodeId = 187083288 #nodes = 115814616 #edges = 5306800261 #exceptions = 1493 #id_blocks_given_up = 0 in 170 minutes [CRAWL_FINISHED]

avg. 48

Follow graph today:
16B edges.
out degree: 2.1
in degree: 1.8
2M > 1k edges


2nd degree: follows of follows. 10 nodes > 1B paths
50k nodes > 100 M paths

\todonote{fill in with actual operation proportions.}



\section{Underview, don't read}
\begin{enumerate}
\item design: I've fleshed out one alternative sharding function, and have a second one brewing. I want another method besides those. 

\item implementation: on top of the graph service architecture (which is itself not implemented yet). For the past week and a half I  worked on a simulator
for the rest of the system that I will use to test and measure what I am doing. Eventually I'll get to try these things in the same data that the team will be testing their own new social graph store.

\item results: I expect to have a set of results be simulation based (eg simulated graph, simulated overall system),  and one set based on actual graph data + actual overall system.
\end{enumerate}
\subsection{Challenges and goals}
A challenge on the design side is a lot of the thinking done may not result in a significantly better scheme, and just provide significantly more complicated one with modest or no performance gains. 

On the implementation side, the Data Services team is currently building this infrastructure so I also am working on a moving target, and it makes it more challenging for me to anchor implementation designs.

For an MIT MEng thesis it is probably enough to present a well informed and technically challenging exploration involving design, implementation and measurements. For Twitter I'd like to contribute something that at least informs the design, but at best provides a viable sharding mechanism specialized enough for the twitter graph that it performs better than general methods and can be used in production.

\section{Design}
\subsection{Background}
Note: some of the numbers (eg on cost of reading all followers, correlation between frequency of fanouts and edge set size for a node) will need updating as I learn them.

Sharding in the graph data store is proposed to be hashing by left endpoint.  ie a mapping like (A,B) -> A -> shard\_id. This way of sharding guarantees edge localy because all edges with the same left vertex shard to the same sharding unit.  There is another design proposal that is also hashing based, but it brings bits from both h(A) and h(B) together to make the mapping less random than a hash by full (A,B). The effect of this scheme is to limit the number of shards all edges of the form (A,*) map to.

In any case, there are two immediate and competing interests. One is minimizing load imbalance, the other minimizing the costs of distribution. (ie one-shard is one extreme, all-shards queries are another one). The 'optimal' scheme from this load point of view depends on actual skews of both the actual degree distribution for the graph as well as the skew in queries to particular pieces of data, and also the relative frequencies of single edge queries (does A follow B) vs multiple edge queries (who follows A).  For example, if single edge queries get(A,B) are overwhelmingly more common than get(A,*) then locality is not as important, and higher numbers of messages across multiple nodes could be tolerated.  As another example, if a lot of individual single edge queries go to edges from the same left vertex A, then spreading them out across shards is best.  Similarly, if nodes have many many followers, then serving everything from a single shard may hinder parallelism. All of these questions depend on the empirical structure of the graph and queries.

The proposed sharding by left node is a simple, clean option. There are throughput targets for different operations, as well as target latencies that need to face these uneven distributions. So a good question is whether sharding by left vertex is good enough. At the 99.99 percentile, the number of followers is ~25000, which means that if a single shard is to hold all of them then a query of the form 'get all followers for A'  requires (2.5 e 4 edges) * (1 e 2 Bytes/edge) = 2.5 e 6 B = 2.5 MB   (x2 to allowing for some memory overhead, besides replication).   Reading this sequentially from Memory takes ~ 250 usec/MB * 5 MB ~ 1 ms. Which is well within the 10 ms bounds.  On the other hand there are nodes in the distribution tail that right now have 10M edges. The same read delay calculation becomes 1 e 7 edges * 1 e 2 bytes/edge = 1 e 9 B = 1 GB, and allowing for some memory overhead, 2GB. ~  500 ms, by far past the limits.  An inverse calculation can be used to find the 'cutoff' at which simply reading from memory is already a bottleneck.  This comes to 200k edges, (percentile 5  nines).

 The argument about reading from memory suggests it is not possible to meet these targets, but there are several counter-arguments that dampen its implications. The first one is that these are the long tails of the degree distribution, so we can allow them to take longer and still meet targets.  The second one is that in reality the 'get all followers of A'  type queries are a smaller fraction than initially apparent: the applications are already designed to make these requests in smaller batches. The third one is that the calculation above points out that memory reads won't be done as fast, but a lot of other things will be worse than that much earlier. The network bandwitdth is presumably lower, and  even capacity of clients to consume the data. Moreover, this kind of query for 'all followers of A' will become less common if a proposed 'selective timeline materialization' strategy becomes used by the rest of the system. There are counterarguments to these points too. One is that this small but influential group of users is of some value beyond simply optimizing for 99.99\% of the cases would reflect. But even strictly based on the numbers. If we mean 99.99 percent of individual <requests> must be below 10ms, then the fact that queries to these particular 0.001\% of <users> are may actually translate to violating the SLA depending on how many queries go to this particular group. (Data on the correlation between query rate and degree is still forthcoming).

Going deeper in the correlation reasoning of the previous paragraph. There are potential interdepencies in 'skew' that I have not considered but could be maybe worth taking a look at in data. Hypothetically, there could be dependencies in the the degree frequency skew and the query frequency for a particular or node edge. For example, the users with the most followers are also likely to be the ones growing the fastest, so insert queries to their nodes may be more frequent. It may also be the case that users with more followers tend to tweet more often, so fanout queries asking for all their followers are executed more often. While these users may be a smaller fraction, the overall percentage of requests made for them is probably larger than 0.001\%.  

There are a few more observations of these types that could be investigated on the actual use logs, and that could be relevant to any design, and a potential part of the project. It could also be these things are just not significant, I'm not sure. While the complexity of this reasoning, the system designs resulting from it need not be complex.

\subsection{Proposal}

Here are a couple of approaches  I have in mind:

\subsubsection{Two-tier sharding:}

This is my simpler, and better thought out method right now. It is influenced a lot by the fine grained partitioning paper in that it exploits the possibility of using explicit lookups in some cases, and a default for others.

The idea in this method is to classify vertices (UIDs) in 2 tiers based on the number of edges and then treat them differently based on tier. For example  queries for users with 0 - 100k  followers would be best served by storing all edges together in the same node, but a method such as hashing (including clustered consistent hashing) would distribute them among several.  Users with > 100k (100k is the cutoff order of magnitude where it is still possible to read fast in a single node) In the current graph there are less than 3k users with this number of followers,  so we can easily store an explicit lookup table (uid -> replica set) for that kind of user, or simply use a different clustered consistent hashing scheme on this set only since here it is expected we distribute work among nodes.  The explicit lookup table still can be done even if the graph grows to 500 M while keeping its degree distribution about the same.  This kind of sharding should improve performance for queries like get(A,*) without really hurting single edge queries or anything other query in particular (at the price of  the overhead of moving things from one tier to another sometimes).

There are several issues to solve in this case. One is to still be able to answer queries by edge. For a vertex A in the 'power' user tier, if we query for (A, B) we won't immediately know where it is.   

Also, different shard units for this same user need to go in different machines, so that we can read their edges in parallel, but this won't be really helpful if the rest of the system serializes going through this sequence. This could be simulated, though.

 Another issue is dealing with the changes in the user graph. There are scenarios where a user moves from one tier to the other. This involves something akin to range splitting (but potentially on a user by user basis) as happens in range partitioning.   When a node goes down this can probably be dealt with just as with the other schemes.  Two tier sharding can be expanding to more than 2 tiers, and how we pick who goes in which tier can be done based not only on degree but arbitrary policies.  

\subsubsection{Social sharding:}
This method is more based on the one explained in the Schism paper. Here I will first look at which pairs of users are often used in intersection queries, then I will construct a graph based on this just like in schism, and try to shard these users together. This way, intersection queries can be pushed down to the nodes.

I have to think about whether other ways to partition this (that use social graph information of some sort), are also  good idea.

The graph exploration and partitioning can be done offline, but we still need to have a concise representation of the look up table available to do the online lookups express the results of any offline algorithms, this is a challenge I have not really come up with a solution for. 

Additionally there is a problem if the graph structure changes a lot over time, ie how do we keep the sharding up to date if every time we update it it may change enough that a lot of work is needed to update it.  Still, the fine grained partitioning paper offers some options for concisely representing /compressing the look up table in some cases. The advantage here is that for queries such as intersect\_edges(A,B), if this kind of query occurs often when A follows B, then by splitting the graph this way we gain the advantages of not just hashing by left-endpoint, but looking up edges(A, *), and edges(B, *) and the subsequent intersection can be done at the node, and only the result set sent back to the API server.

Lastly, besides the the two main queries, the are other types of queries such as "get(A,) Union get(B, *)" or "get(A,, follows) Intersection get(B, *, follower)". This last query occurs for example when a user visits the timeline of another.  Since presumably this happens more for users that follow one another, then encouraging the placement of adjacent nodes in the same shard enables us to push intersections into single nodes a larger fraction of the time. There are also more experimental kinds of operations that do not exist at this point such as explore 2 hops away.

\subsubsection{other}

There are other important families of queries I have not though as much about, such as time based queries such as get\_follers(A, within last 3 days).  these offer other areas to think about. Other ideas are 

\section{Implementation}
\subsection{Targets}

\begin{enumerate}
\item Implementing hashing strategies (currently implementing the two tier strategy)
\item Working around the current sharding library limitations as I realize them, and making sure  I understand the interface to it. (In progress)
\item Implementing some simulation classes to benchmark my stuff  independently of whether there is a fully working system (also just for testing). (In progress)
\item Implementing the other sharding strategies (ie some may require offline learning of some graph properties), may include using external tools to generate some graphs and partition them.

\end{enumerate}

\subsection{Benchmarks}
\subsubsection{Background}
The goal here is to measure how much better or worse these perform, after fixing the number of machines, based on the empirical patterns found earlier in the design part.  Workloads could be derived from real operation data or hypothetical data with skews like done in the PNUTS paper. Reading from different papers how they benchmark things would help.
\subsubsection{Proposal}


To benchmark the two-tier hash strategy 

\begin{enumerate}
\item Will want to see how the viability of the strategy (eg amount of state needed for lookup table) changes as the graph changes. Eg. in simulation vary the degree skew.
\item Will want to vary the workload composition (Eg \% of fanouts, intersections)
\item Will want to quantify time and space cost of running the custom shard code vs. will want to quantify performance of the full graph data system  with custom shard.
\item Will want to quantify cost of having to move data around every now and then (since you need this when you don't hash)
in the case of a strategy where I need to crawl the graph offline, benchmark the process itself.
\end{enumerate}

Another way to compare methods is by comparing resources needed to achieve the same  performance requirements. (vs comparing the results achieved with the same resources).

Finally, factors such as bottlenecks in the rest of the system may hinder observing the effects desired. I can modify the simulator to show that, but could affect other results.
\nocite{*}
\bibliography{bib/more}

\end{document}
